# Spark Configuration for Iceberg + Polaris + LocalStack
# Used by tabulario/spark-iceberg image
#
# Documentation: https://iceberg.apache.org/docs/latest/spark-configuration/

# ==============================================================================
# Iceberg Extensions
# ==============================================================================
spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions

# ==============================================================================
# Polaris REST Catalog Configuration
# ==============================================================================
spark.sql.catalog.polaris=org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.polaris.type=rest
spark.sql.catalog.polaris.uri=http://polaris:8181/api/catalog
spark.sql.catalog.polaris.warehouse=warehouse

# Default catalog for unqualified table references
spark.sql.defaultCatalog=polaris

# ==============================================================================
# S3/LocalStack Configuration (via Hadoop S3A)
# ==============================================================================
spark.hadoop.fs.s3a.endpoint=http://localstack:4566
spark.hadoop.fs.s3a.access.key=test
spark.hadoop.fs.s3a.secret.key=test
spark.hadoop.fs.s3a.path.style.access=true
spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.connection.ssl.enabled=false

# S3A performance tuning
spark.hadoop.fs.s3a.fast.upload=true
spark.hadoop.fs.s3a.fast.upload.buffer=bytebuffer
spark.hadoop.fs.s3a.multipart.size=104857600

# ==============================================================================
# Iceberg Performance Settings
# ==============================================================================
# Write settings
spark.sql.catalog.polaris.io-impl=org.apache.iceberg.aws.s3.S3FileIO
spark.sql.catalog.polaris.s3.endpoint=http://localstack:4566
spark.sql.catalog.polaris.s3.path-style-access=true

# Vectorized reads
spark.sql.iceberg.vectorization.enabled=true

# ==============================================================================
# Spark SQL Settings
# ==============================================================================
# Enable ANSI mode for stricter SQL behavior
spark.sql.ansi.enabled=true

# Shuffle partitions (reduce for local testing)
spark.sql.shuffle.partitions=4

# Adaptive query execution
spark.sql.adaptive.enabled=true
spark.sql.adaptive.coalescePartitions.enabled=true

# ==============================================================================
# Spark Application Settings
# ==============================================================================
spark.app.name=floe-spark-iceberg
spark.master=local[*]

# Memory settings for local testing
spark.driver.memory=2g
spark.executor.memory=2g

# Event logging for Spark History Server
spark.eventLog.enabled=true
spark.eventLog.dir=/home/iceberg/spark-events
