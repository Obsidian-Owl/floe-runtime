# Research: Consumption Layer (floe-cube)

**Feature Branch**: `005-consumption-layer`
**Date**: 2025-12-18

## Research Summary

This document captures research findings for implementing the floe-cube consumption layer.

---

## 1. cube_dbt Package Integration

### Decision
Use Cube's built-in dbt integration via YAML/Jinja templates rather than a standalone Python cube_dbt package.

### Rationale
- Cube's dbt integration works through Jinja templates in YAML data models
- The `cube_dbt` namespace provides functions like `as_cube()`, `as_dimensions()`, `as_measures()`
- Templates read from dbt manifest.json to generate Cube schemas
- This is a Node.js/Cube runtime feature, not a Python package

### Alternative Considered
- **Standalone Python cube_dbt package**: Does not exist as a pip-installable package
- **Manual parsing of dbt manifest.json**: More work, less maintainable

### Implementation Approach
floe-cube will generate Cube YAML schema files that use Jinja templates:

```yaml
# Generated by floe-cube from CompiledArtifacts
cubes:
  - name: {{ model.name }}
    sql_table: {{ model.relation_name }}

    dimensions:
      {% for column in model.columns %}
      - name: {{ column.name }}
        sql: {{ column.name }}
        type: {{ column.data_type | cube_type }}
        {% if column.meta.cube.primary_key %}
        primary_key: true
        {% endif %}
      {% endfor %}

    measures:
      {% for measure in model.meta.cube.measures %}
      - name: {{ measure.name }}
        sql: {{ measure.sql }}
        type: {{ measure.type }}
      {% endfor %}
```

### dbt Meta Tags for Cube Integration

dbt models should use these meta tags for Cube customization:

```yaml
# dbt model meta configuration
models:
  - name: orders
    meta:
      cube:
        primary_key: id
        measures:
          - name: count
            type: count
          - name: total_amount
            sql: amount
            type: sum
    columns:
      - name: id
        meta:
          cube:
            primary_key: true
      - name: status
        meta:
          cube:
            type: string
```

---

## 2. Cube Configuration Structure

### Decision
Generate cube.js configuration file in JavaScript format, using environment variables for secrets.

### Rationale
- Cube's native configuration format is JavaScript (cube.js)
- Environment variables provide secure secret handling
- Supports all required database drivers

### Configuration Template

```javascript
// Generated by floe-cube from CompiledArtifacts
module.exports = {
  // Database configuration
  dbType: process.env.CUBEJS_DB_TYPE || '{{ database_type }}',

  // Database-specific settings (varies by driver)
  {% if database_type == 'postgres' %}
  dbHost: process.env.CUBEJS_DB_HOST,
  dbPort: process.env.CUBEJS_DB_PORT || '5432',
  dbName: process.env.CUBEJS_DB_NAME,
  dbUser: process.env.CUBEJS_DB_USER,
  dbPassword: process.env.CUBEJS_DB_PASS,
  {% elif database_type == 'snowflake' %}
  dbAccount: process.env.CUBEJS_DB_SNOWFLAKE_ACCOUNT,
  dbWarehouse: process.env.CUBEJS_DB_SNOWFLAKE_WAREHOUSE,
  dbDatabase: process.env.CUBEJS_DB_NAME,
  dbSchema: process.env.CUBEJS_DB_SCHEMA,
  {% elif database_type == 'bigquery' %}
  dbProjectId: process.env.CUBEJS_DB_BQ_PROJECT_ID,
  dbKeyFile: process.env.CUBEJS_DB_BQ_KEY_FILE,
  {% elif database_type == 'trino' %}
  dbHost: process.env.CUBEJS_DB_HOST,
  dbPort: process.env.CUBEJS_DB_PORT || '8080',
  dbCatalog: process.env.CUBEJS_DB_CATALOG,
  dbSchema: process.env.CUBEJS_DB_SCHEMA,
  {% endif %}

  // API configuration
  apiSecret: process.env.CUBEJS_API_SECRET,
  devMode: process.env.CUBEJS_DEV_MODE === 'true',

  // SQL API (Postgres wire protocol)
  sqlPort: {{ sql_port | default(15432) }},

  // Pre-aggregations
  preAggregationsSchema: process.env.CUBEJS_PRE_AGGREGATIONS_SCHEMA || 'pre_aggregations',

  // Telemetry
  telemetry: false,
};
```

### Database Driver Support

| database_type | Cube Driver | Connection Parameters |
|--------------|-------------|----------------------|
| postgres | postgres | host, port, database, user, password |
| snowflake | snowflake | account, warehouse, database, schema, user, password |
| bigquery | bigquery | projectId, keyFile, dataset |
| databricks | databricks | host, token, httpPath |
| trino | trino | host, port, catalog, schema |

---

## 3. JWT-Based Row-Level Security

### Decision
Use Cube's built-in JWT authentication with queryRewrite for user-managed, role-based filtering.

### Rationale
- Cube natively supports JWT authentication via `checkAuth` context
- `queryRewrite` allows injecting user-defined filters into every query
- Standard JWT libraries handle signature verification
- Users configure which JWT claims map to which filter columns (e.g., organization_id, department, region)

### Security Model Distinction

**Important**: This is **not** SaaS tenant isolation. Row-level security in floe-cube is:
- **User-managed**: Users define filter columns and JWT claim mappings
- **Role-based**: Access determined by user attributes, not infrastructure isolation
- **Flexible**: Supports any filter column (organization_id, department, region, etc.)

The future Floe SaaS Control Plane will provide **infrastructure-level** tenant isolation (separate environments per customer), which is a different concern.

### Implementation Pattern

```javascript
// cube.js - Security configuration
// filter_column is user-configurable (e.g., "organization_id", "department")
const FILTER_COLUMN = process.env.CUBEJS_SECURITY_FILTER_COLUMN || 'organization_id';
const FILTER_CLAIM = process.env.CUBEJS_SECURITY_FILTER_CLAIM || 'organization_id';

module.exports = {
  // JWT verification
  checkAuth: (req, auth) => {
    // Cube verifies JWT signature using CUBEJS_API_SECRET
    // Extract filter claim from JWT (user-configurable)
    if (!auth || !auth.u || !auth.u[FILTER_CLAIM]) {
      throw new Error(`Missing required claim: ${FILTER_CLAIM}`);
    }
    return auth;
  },

  // Inject user-defined filter into all queries
  queryRewrite: (query, { securityContext }) => {
    const filterValue = securityContext[FILTER_CLAIM];
    if (!filterValue) {
      throw new Error(`Row-level security requires ${FILTER_CLAIM}`);
    }

    // Add filter to query using configured column
    query.filters = (query.filters || []).concat({
      member: `${query.measures[0].split('.')[0]}.${FILTER_COLUMN}`,
      operator: 'equals',
      values: [filterValue],
    });

    return query;
  },

  // Map JWT claims to security context
  contextToAppId: ({ securityContext }) => {
    return securityContext[FILTER_CLAIM];
  },
};
```

### JWT Token Structure (Example)

```json
{
  "sub": "user-123",
  "iat": 1702900000,
  "exp": 1702903600,
  "u": {
    "organization_id": "org_abc",
    "department": "engineering",
    "roles": ["analyst"]
  }
}
```

Users configure which claim to use for filtering (e.g., `organization_id` or `department`).

---

## 4. Observability: OpenTelemetry vs OpenLineage

### Understanding the Distinction

**OpenTelemetry** and **OpenLineage** serve complementary but distinct purposes:

| Aspect | OpenTelemetry | OpenLineage |
|--------|---------------|-------------|
| **Purpose** | Operational observability | Data lineage |
| **Question answered** | "How is the system performing?" | "What data is being accessed?" |
| **Data captured** | Traces, spans, latency, errors | Datasets, jobs, run states |
| **Consumers** | SRE/DevOps (Jaeger, Grafana) | Data governance (Marquez, DataHub) |
| **Protocol** | OTLP (gRPC/HTTP) | HTTP REST |
| **When emitted** | Real-time during execution | At query lifecycle events |

Both are required for a complete observability story per the floe-runtime architecture.

---

## 5. OpenTelemetry Integration

### Decision
Use opentelemetry-python SDK to emit traces with W3C Trace Context propagation.

### Rationale
- OpenTelemetry is the project standard for operational observability (per 00-overview.md)
- W3C Trace Context enables distributed tracing across services
- OTLP exporter supports Jaeger, Grafana Tempo, and other backends
- Non-blocking emission via BatchSpanProcessor

### Implementation Pattern

```python
from __future__ import annotations

from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter
from opentelemetry.propagate import extract
from opentelemetry.trace import SpanKind, Status, StatusCode

# Initialize tracer
provider = TracerProvider()
provider.add_span_processor(
    BatchSpanProcessor(OTLPSpanExporter(endpoint="http://localhost:4317"))
)
trace.set_tracer_provider(provider)
tracer = trace.get_tracer("floe-cube")


def trace_query(
    cube_name: str,
    measures: list[str],
    dimensions: list[str],
    filter_count: int,  # NOT filter values (sensitive)
    headers: dict[str, str],  # For trace context propagation
) -> trace.Span:
    """Create trace span for query execution.

    Security: Never include filter values, JWT claims, or row data in spans.
    """
    # Extract parent context from incoming request headers
    context = extract(headers)

    with tracer.start_as_current_span(
        "cube.query",
        context=context,
        kind=SpanKind.SERVER,
    ) as span:
        # Safe metadata only - no sensitive data
        span.set_attribute("cube.name", cube_name)
        span.set_attribute("cube.measures_count", len(measures))
        span.set_attribute("cube.dimensions_count", len(dimensions))
        span.set_attribute("cube.filter_count", filter_count)  # Count, not values!
        return span


def record_query_result(
    span: trace.Span,
    success: bool,
    row_count: int | None = None,
    error_type: str | None = None,
) -> None:
    """Record query result in span."""
    if success:
        span.set_attribute("cube.row_count", row_count or 0)
        span.set_status(Status(StatusCode.OK))
    else:
        span.set_attribute("cube.error_type", error_type or "unknown")
        span.set_status(Status(StatusCode.ERROR))
```

### Span Hierarchy

```
cube.query (root span from client request)
├── cube.parse (query parsing and validation)
├── cube.security (JWT validation, filter injection)
├── cube.execute (database query execution)
│   └── database.query (child span for actual DB call)
└── cube.response (result serialization)
```

---

## 6. OpenLineage Integration

### Decision
Use openlineage-python SDK to emit events, with non-blocking emission and graceful degradation.

### Rationale
- openlineage-python is the official Python SDK (already in pyproject.toml)
- HTTP transport supports custom endpoints (Marquez, custom backends)
- Non-blocking approach prevents lineage failures from impacting queries
- Aligns with spec clarification: "Log warning and continue query execution"

### Implementation Pattern

```python
from __future__ import annotations

import logging
from datetime import datetime, timezone
from typing import Any
from uuid import uuid4

from openlineage.client import OpenLineageClient
from openlineage.client.event_v2 import Dataset, Job, Run, RunEvent, RunState
from openlineage.client.facet_v2 import sql_job

logger = logging.getLogger(__name__)


class QueryLineageEmitter:
    """Emit OpenLineage events for Cube queries (non-blocking)."""

    def __init__(self, endpoint: str, namespace: str = "floe-cube") -> None:
        self.client = OpenLineageClient(url=endpoint)
        self.namespace = namespace

    def emit_start(self, query_id: str, cube_name: str, sql: str) -> None:
        """Emit START event when query begins."""
        try:
            event = RunEvent(
                eventType=RunState.START,
                eventTime=datetime.now(timezone.utc).isoformat(),
                run=Run(runId=query_id),
                job=Job(namespace=self.namespace, name=f"cube.{cube_name}.query"),
                inputs=[Dataset(namespace=self.namespace, name=cube_name)],
                outputs=[],
            )
            event.run.facets = {"sql": sql_job.SQLJobFacet(query=sql)}
            self.client.emit(event)
        except Exception as e:
            logger.warning(f"Failed to emit OpenLineage START event: {e}")

    def emit_complete(self, query_id: str, cube_name: str, row_count: int) -> None:
        """Emit COMPLETE event when query succeeds."""
        try:
            event = RunEvent(
                eventType=RunState.COMPLETE,
                eventTime=datetime.now(timezone.utc).isoformat(),
                run=Run(runId=query_id),
                job=Job(namespace=self.namespace, name=f"cube.{cube_name}.query"),
                inputs=[Dataset(namespace=self.namespace, name=cube_name)],
                outputs=[],
            )
            self.client.emit(event)
        except Exception as e:
            logger.warning(f"Failed to emit OpenLineage COMPLETE event: {e}")

    def emit_fail(self, query_id: str, cube_name: str, error: str) -> None:
        """Emit FAIL event when query fails (without exposing sensitive data)."""
        try:
            # Sanitize error message - remove sensitive info
            safe_error = self._sanitize_error(error)
            event = RunEvent(
                eventType=RunState.FAIL,
                eventTime=datetime.now(timezone.utc).isoformat(),
                run=Run(runId=query_id),
                job=Job(namespace=self.namespace, name=f"cube.{cube_name}.query"),
                inputs=[Dataset(namespace=self.namespace, name=cube_name)],
                outputs=[],
            )
            self.client.emit(event)
        except Exception as e:
            logger.warning(f"Failed to emit OpenLineage FAIL event: {e}")

    def _sanitize_error(self, error: str) -> str:
        """Remove sensitive information from error messages."""
        # Remove potential secrets, credentials, connection strings
        sanitized = error
        # Pattern-based sanitization would go here
        return sanitized[:500]  # Truncate to prevent large payloads
```

---

## 7. Pre-Aggregation Configuration

### Decision
Use Cube's native pre-aggregation with cron-based refresh schedules stored in S3.

### Rationale
- Cube Store handles pre-aggregation storage and query routing
- S3-compatible storage (LocalStack in dev, real S3 in prod)
- Cron syntax aligns with ConsumptionConfig.pre_aggregations.refresh_schedule

### Configuration Pattern

Pre-aggregations are defined per-cube in the schema:

```yaml
cubes:
  - name: orders
    sql_table: iceberg.default.orders

    pre_aggregations:
      - name: orders_by_day
        measures:
          - count
          - total_amount
        dimensions:
          - status
        time_dimension: created_at
        granularity: day
        refresh_key:
          every: "{{ refresh_schedule }}"  # From CompiledArtifacts
        external: true  # Use Cube Store
```

Environment configuration for storage:

```bash
# Pre-aggregation storage (S3)
CUBEJS_DB_EXPORT_BUCKET_TYPE=s3
CUBEJS_DB_EXPORT_BUCKET=s3://cube-preaggs
CUBEJS_DB_EXPORT_BUCKET_AWS_KEY=${AWS_ACCESS_KEY_ID}
CUBEJS_DB_EXPORT_BUCKET_AWS_SECRET=${AWS_SECRET_ACCESS_KEY}
CUBEJS_DB_EXPORT_BUCKET_AWS_REGION=${AWS_REGION}
```

---

## 8. API Endpoints

### Decision
Use Cube's built-in REST, GraphQL, and SQL APIs with standard ports.

### Rationale
- REST API (port 4000): JSON query format, pagination via limit/offset
- GraphQL API (port 4000/graphql): Schema introspection, type-safe queries
- SQL API (port 15432): Postgres wire protocol for BI tools

### API Summary

| API | Endpoint | Authentication | Use Case |
|-----|----------|---------------|----------|
| REST | `http://host:4000/cubejs-api/v1/load` | Bearer JWT | Application queries |
| GraphQL | `http://host:4000/cubejs-api/graphql` | Bearer JWT | Frontend with types |
| SQL | `postgresql://host:15432` | Username/Password (JWT-derived) | BI tools (Tableau, Metabase) |

### REST Query Example

```json
POST /cubejs-api/v1/load
Authorization: Bearer <jwt-token>

{
  "measures": ["Orders.count", "Orders.totalAmount"],
  "dimensions": ["Orders.status"],
  "timeDimensions": [{
    "dimension": "Orders.createdAt",
    "granularity": "day",
    "dateRange": "Last 7 days"
  }]
}
```

---

## 9. File Watcher for Manifest Sync

### Decision
Use Python watchdog library to detect manifest.json changes and trigger sync.

### Rationale
- watchdog is a mature, cross-platform file system event library
- Can be configured as a Dagster sensor or standalone process
- Aligns with spec clarification: "Automatic on manifest.json change detection"

### Implementation Approach

```python
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

class ManifestChangeHandler(FileSystemEventHandler):
    def __init__(self, sync_callback):
        self.sync_callback = sync_callback

    def on_modified(self, event):
        if event.src_path.endswith('manifest.json'):
            self.sync_callback()
```

Alternative: Post-dbt hook in dbt_project.yml that triggers sync command.

---

## Summary of Key Decisions

| Area | Decision | Rationale |
|------|----------|-----------|
| dbt Integration | Jinja templates in YAML schemas | Native Cube approach |
| Configuration | JavaScript cube.js with env vars | Secure, standard format |
| Security | JWT with queryRewrite | Built-in Cube feature |
| OpenTelemetry | opentelemetry-python, W3C context | Operational observability standard |
| OpenLineage | openlineage-python, non-blocking | Data lineage standard |
| Pre-aggs | Cube Store with S3 storage | Managed caching |
| Sync Trigger | watchdog file watcher | Automatic detection |
